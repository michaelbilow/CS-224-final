__author__ = 'michael'

import os
import sys
from create_hash_table import read_chromosome, hash_chromosome
import numpy as np
import math
from collections import defaultdict
import swalign
import string


MIN_DIST_BETWEEN_READS = 80
MAX_DIST_BETWEEN_READS = 120
INDEL_CUTOFF = 20
SCORING = swalign.NucleotideScoringMatrix()
ALIGNER = swalign.LocalAlignment(SCORING, globalalign=True, gap_penalty=-5)
UPPERCASE = set(string.ascii_uppercase)


def locations_to_peaks(locations, key_length, bp_error_probability=.02):
    """
    Converts the start locations generated by a single read
    into a dict of probabilities.

    Uses an HMM-like rule to give the likelihood of a particular string.
    """

    exact_match_probability = (1.0 - bp_error_probability) ** key_length
    exact_match_log_p = math.log(exact_match_probability)
    average_error_log_p = math.log(1.0 - exact_match_probability) - key_length * math.log(4)
    #  First term: leftover probability, second term: number of possible key_length strings
    bp_error_log_p = math.log(bp_error_probability)

    peaks = [([(np.nan, np.nan, np.nan, np.nan)],  # Peaks have the form: [[list of start locations],
              #     start location = (chromosome index, implied start point,
              #                       actual start point, end point)
              0,  # log_probability,
              ['E'])]  # string of whether the match at this position is perfect or not,

    # We initialize with np.nan to stand in for
    # all other non-aligning sequences in the genome.
    for i in range(len(locations)):
        location_list = locations[i]
        implied_start_location_list = [x[:-1] for x in location_list]
        location_used = [False for x in range(len(location_list))]
        default_error_log_p = i * average_error_log_p
        new_peaks = []
        for j in range(len(peaks)):
            peak = peaks[j]
            peak_history = peak[0]
            log_p = peak[1]
            match_qualities = peak[2]
            current_start_and_end_loc = peak_history[-1]  # The last start_loc is where the current one starts.
            implied_start_loc = current_start_and_end_loc[:2]  #
            chrom_distances = [chromosome_signed_distance(loc, implied_start_loc)
                               for loc in implied_start_location_list]

            match_indices = [k for k in range(len(chrom_distances)) if chrom_distances[k] == 0]
            assert len(match_indices) <= 1  # There can be at most one perfect match.
            if match_indices:
                match_index = match_indices[0]
                match_location = location_list[match_index]
                new_peak_history = peak_history + [match_location]
                new_log_p = log_p + exact_match_log_p
                new_match_qualities = match_qualities + ['M']
                new_peak = (new_peak_history, new_log_p, new_match_qualities)
                new_peaks.append(new_peak)
                location_used[match_index] = True
            else:  # If there is no perfect match, extend the match with an error
                error_location = (current_start_and_end_loc[0],
                                  current_start_and_end_loc[1],
                                  current_start_and_end_loc[3],
                                  current_start_and_end_loc[3] + key_length)
                error_peak_history = peak_history + [error_location]
                error_peak_log_p = log_p + average_error_log_p
                error_match_quality = match_qualities + ['E']
                error_peak = (error_peak_history, error_peak_log_p, error_match_quality)
                new_peaks.append(error_peak)

            indel_indices = [k for k in range(len(chrom_distances)) if 0 < abs(chrom_distances[k]) <= INDEL_CUTOFF]

            for indel_index in indel_indices:
                ## Create new peaks with the indel, and one where it is interpreted as an error
                indel_location = location_list[indel_index]
                indel_peak_start_locs = peak_history + [indel_location]
                indel_length = chrom_distances[indel_index]
                indel_peak_log_p = log_p + exact_match_probability + indel_length * bp_error_log_p
                if indel_length > 0:
                    indel_match_qualities = match_qualities + ['I' + str(indel_length)]
                elif indel_length < 0:
                    indel_match_qualities = match_qualities + ['D' + str(abs(indel_length))]
                indel_peak = (indel_peak_start_locs, indel_peak_log_p, indel_match_qualities)
                new_peaks.append(indel_peak)

        ## Now, we need to add in peaks for the unused locations
        for j in range(len(location_list)):
            if location_used[j]:  # If the peak had an exact match, we assume that's the correct place for it to align.
                continue
            else:  # If not, we construct a new sequence of errors followed by a single match.
                match_location = location_list[j]
                new_peak_history = [(match_location[0],
                                     match_location[1],
                                     match_location[1] + key_length * k,
                                     match_location[1] + key_length * (k+1))
                                    for k in range(i)]
                new_peak_history += [match_location]
                new_peak_log_p = default_error_log_p + exact_match_log_p
                new_peak_match_qualities = ['E'] * i + ['M']
                new_peak = (new_peak_history, new_peak_log_p, new_peak_match_qualities)
                new_peaks.append(new_peak)

        peaks = new_peaks

    return peaks


def generate_implied_start_sequence(location, key_length, i):
    chromosome = location[0]
    implied_start_loc = location[1]

    new_locations = [(chromosome,
                      implied_start_loc,
                      implied_start_loc + j * key_length,
                      implied_start_loc + (j + 1) * key_length)
                     for j in range(i)]

    return new_locations


def chromosome_signed_distance(loc1, loc2):
    """
    Computes a "chromosomal" distance between two locations of the form
    loc = (chromsome number, chromosome coordinate)
    where the two reads are considered an infinite distance apart if
    they are on different chromosomes
    """
    if loc1[0] != loc2[0]:
        return np.inf
    else:
        return loc1[1] - loc2[1]


def map_end(read_end, key_length, genome_hash):
    """
    Cut the read into disjoint pieces of length
    key_length, and try to align them using the hash.

    Input:
    read_end,    the bases in one end of a paired-end read
    key_length,  the length of the keys used in the genome_hash
    genome_hash, a hash of the reference genome that returns the
                 starting position of the match for each
                 of the exact matches of each key in the genome.

    Output: [list of peaks] peaks defined up top.
    """
    all_locations = []
    for i in range(len(read_end) / key_length):
        offset = i * key_length
        key = read_end[offset: offset + key_length]
        locations = [(start_loc[0],  # The chromosome that the read is on
                      start_loc[1] - offset,  # The "implied start location" of the read
                      start_loc[1],  # The actual start location of the read
                      start_loc[1] + key_length)  # The actual end of the read.
                     for start_loc in genome_hash[key]]
        all_locations.append(locations)
        print locations
    print
    peaks = locations_to_peaks(all_locations, key_length)
    for p in peaks:
        print p
    print '\n'

    return peaks


def smith_waterman(peak, read, reference, key_length):
    """
    Does Smith-Waterman dynamic-programming alignment and returns the
    most likely global alignment of the reads read1 and read2, and
    returns the CIGAR representation of the output

    Only performs alignment between perfectly matching pieces.
    """

    peak_history, log_p, match_qualities = peak
    ref_start_point = peak_history[0][1]

    cigar_pieces = []
    ref_alignment_completed = ref_start_point
    ref_alignment_frontier = ref_start_point
    read_alignment_completed = 0
    read_alignment_frontier = 0

    for i in range(len(peak_history)):
        current_piece = peak_history[i]
        current_start = current_piece[2]
        current_end = current_piece[3]
        match_quality = match_qualities[i]

        if any(x in match_quality for x in "MDI"):
            ## If it's a match, end of an insertion, or deletion, we're definitely going to alignment
            ## through the end of the current read

            if ref_alignment_frontier != ref_alignment_completed or any(x in match_quality for x in "DI"):
                read_alignment_frontier += key_length
                ref_alignment_frontier = current_end
                # We hit the end of a run of imperfect matches, or we hit an insertion or deletion.
                ref_piece = reference[ref_alignment_completed: ref_alignment_frontier]
                read_piece = read[read_alignment_completed: read_alignment_frontier]
                new_alignment = ALIGNER.align(ref_piece, read_piece).extended_cigar_str
                cigar_pieces.append(new_alignment)
            else:
                # We're in the middle of a run of perfect matches.
                cigar_pieces.append(str(key_length) + 'M')
                read_alignment_frontier += key_length
                ref_alignment_frontier = current_end
            ref_alignment_completed = ref_alignment_frontier
            read_alignment_completed = read_alignment_frontier
        else:
            ref_alignment_frontier = current_end
            read_alignment_frontier += key_length
            if i == len(peak_history) - 1:
                ref_piece = reference[ref_alignment_completed:ref_alignment_frontier]
                read_piece = read[read_alignment_completed:]
                new_alignment = ALIGNER.align(ref_piece, read_piece).extended_cigar_str
                cigar_pieces.append(new_alignment)

    extended_cigar = roll(cigar_pieces)

    return extended_cigar


def roll(cigar_pieces):
    """
    Joins multiple CIGAR-formatted things together into a single
    correctly CIGAR-formatted string
    """
    rolled_cigar = ''
    unfinished_piece = ['', '']  # First coordinate is the run length second is the match type.
    for i in range(len(cigar_pieces)):
        cigar_piece = cigar_pieces[i]
        letter_indices = [x for x in range(len(cigar_piece)) if cigar_piece[x] in UPPERCASE]
        first_match_type = cigar_piece[letter_indices[0]]
        if len(letter_indices) == 1:
            first_match_run = int(cigar_piece[:letter_indices[0]])
            if unfinished_piece[1] == first_match_type:
                unfinished_piece[0] += first_match_run
            else:
                rolled_cigar += ''.join([str(x) for x in unfinished_piece])
                unfinished_piece = [first_match_run, first_match_type]
        else:
            first_match_run = int(cigar_piece[:letter_indices[0]])
            middle_cigar_piece = cigar_piece[letter_indices[0] + 1: letter_indices[-2] + 1]
            last_match_type_index = letter_indices[-1]
            if unfinished_piece[1] == first_match_type:
                unfinished_piece[0] += first_match_run
                rolled_cigar += ''.join([str(x) for x in unfinished_piece])
            else:
                rolled_cigar += ''.join([str(x) for x in unfinished_piece])
                rolled_cigar += ''.join([str(x) for x in (first_match_run, first_match_type)])
            rolled_cigar += middle_cigar_piece
            last_match_type = cigar_piece[last_match_type_index]
            last_match_run = int(cigar_piece[letter_indices[-2] + 1: -1])
            unfinished_piece = [last_match_run, last_match_type]

        if i == len(cigar_pieces) - 1:
            rolled_cigar += ''.join([str(x) for x in unfinished_piece])

    return rolled_cigar


def pair_peaks(peaks1, peaks2, read_length):
    peaks1 = sorted(peaks1, key=lambda x: -x[1])
    peaks2 = sorted(peaks2, key=lambda x: -x[1])
    peak_pairs = []
    for peak1 in peaks1:
        for peak2 in peaks2:
            start_loc1 = peak1[0][0]
            start_loc2 = peak2[0][0]
            start_dist = abs(chromosome_signed_distance(start_loc1, start_loc2))
            if MIN_DIST_BETWEEN_READS <= start_dist - read_length <= MAX_DIST_BETWEEN_READS:  # This criteria should be
                # made flexible eventually
                peak_pairs.append((peak1, peak2))
                break  # Because the peaks are sorted in order, we take the one with the highest probability.
    return peak_pairs


def map_read(paired_end_read, key_length, hash_table, reference):
    """
    Maps a single paired-end read to the genome.
    Each end is mapped to a set of "probabilistic" peaks (the numbers aren't really probabilities)
    Then the ends are aligned to each other, and the alignment is returned.
    """
    end1 = paired_end_read[0]
    end2 = paired_end_read[1]
    peaks1 = map_end(end1, key_length, hash_table)
    peaks2 = map_end(end2, key_length, hash_table)
    paired_peaks_list = pair_peaks(peaks1, peaks2, len(end1))
    if len(paired_peaks_list) == 0:
        print 'No Alignment\n\n'
    elif len(paired_peaks_list) != 1:
        print 'BOOOOOOOOOPS\n\n\n\n\n\n'
    else:
        paired_peaks = paired_peaks_list[0]
        print paired_peaks[0]
        print paired_peaks[1]
        alignment1 = smith_waterman(paired_peaks[0], end1, reference, key_length)
        print end1, alignment1
        alignment2 = smith_waterman(paired_peaks[1], end2, reference, key_length)
        print end2, alignment2
    print '------------------------\n\n'
    return


def read_and_map_reads(reads_fn, key_length, genome_hash, ref_seq):
    """
    Maps a whole bunch of paired-end reads to a reference genome.
    """
    with open(reads_fn, 'r') as reads_file:
        reads_file.readline()
        reads_file.readline()
        count = 0
        for line in reads_file:
            paired_end_read = line.strip().split(',')
            print count
            count += 1
            if count <= 56:
                continue
            map_read(paired_end_read, key_length, genome_hash, ref_seq)
            if count > 155:
                break


if __name__ == "__main__":
    input_folder = './EE_genome'
    ref = 'ref/ref_genomeEExample.txt'
    reads = 'reads/reads_genomeEExample.txt'
    ref_fn = os.path.join(input_folder, ref)
    reads_fn = os.path.join(input_folder, reads)
    key_size = 10
    index, seq = read_chromosome(ref_fn)
    seq_dict = {index: seq}
    my_hash = hash_chromosome(index, seq, key_size)

    read_and_map_reads(reads_fn, key_size, my_hash, seq)