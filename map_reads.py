__author__ = 'michael'

import os
import sys
from create_hash_table import hash_reference
import numpy as np
import math
from collections import defaultdict

MIN_DIST_BETWEEN_READS = 80
MAX_DIST_BETWEEN_READS = 120
INDEL_CUTOFF = 20

def locations_to_peaks(locations, bp_error_probability=.02):
    """
    Converts the start locations generated by a single read
    into a dict of probabilities.

    Uses an HMM-like rule to give the likelihood of a particular string.
    """

    exact_match_probability = (1.0 - bp_error_probability)**key_length
    exact_match_log_p = math.log(exact_match_probability)
    average_error_log_p = math.log(1.0 - exact_match_probability) - key_length * math.log(4)
                              #  First term: leftover probability, second term: number of possible key_length strings
    bp_error_log_p = math.log(bp_error_probability)

    peaks = [([np.nan], 0, ['I'])]  # Peaks have the form:
                                  # [[list of start locations],
                                  # log_probability,
                                  # string of whether the match at this position is perfect or not,]
                                  #  We initialize with np.nan to stand in for
                                  # all other non-aligning sequences in the genome.
    for i in range(len(locations)):
        location_list = locations[i]
        default_error_probability = i*average_error_log_p
        new_peaks = []
        for j in range(len(peaks)):
            peak = peaks[j]
            start_locs = peak[0]
            log_p = peak[1]
            match_qualities = peak[2]
            current_start_loc = start_locs[-1]
            if current_start_loc in location_list:
                new_start_locs = start_locs + [current_start_loc]
                new_log_p = log_p + exact_match_log_p
                new_match_qualities = match_qualities + ['M']
                new_peak = (new_start_locs, new_log_p, new_match_qualities)
                new_peaks.append(new_peak)
            else:  # It may be an error or an indel
                error_peak_start_locs = start_locs + [current_start_loc]
                error_peak_log_p = log_p + average_error_log_p
                error_match_quality = match_qualities + ['E']
                error_peak = (error_peak_start_locs, error_peak_log_p, error_match_quality)
                new_peaks.append(error_peak)
                indel_distances = [abs(current_start_loc - loc) for loc in location_list]
                indel_locations = [location_list[k] for k in range(len(location_list))
                                   if indel_distances[k] < INDEL_CUTOFF]
                for indel_location in indel_locations:
                    ## Create new peaks with the indel, and one where it is interpreted as an error
                    indel_peak_start_locs = start_locs + [indel_location]
                    indel_length = current_start_loc - indel_location
                    indel_peak_log_p = log_p + exact_match_probability + indel_length * bp_error_log_p
                    if indel_length > 0:
                        indel_match_qualities = match_qualities + ['I' + str(indel_length)]
                    elif indel_length < 0:
                        indel_match_qualities = match_qualities + ['D' + str(abs(indel_length))]
                    indel_peak = (indel_peak_start_locs, indel_peak_log_p, indel_match_qualities)
                    new_peaks.append(indel_peak)

                    new_peaks += [indel_peak, error_peak]

        peaks = new_peaks
        if not peaks:
            current_start_locations = [peak[0][-1] for peak in peaks]
        else:
            current_start_locations = []
        unused_locations = set(location_list) - set(current_start_locations)

        for location in unused_locations:
            new_peak_start_locs = [location for x in range(i+1)]            # Assume the sequence starts right
                                                                            # at the unused location
            new_peak_log_p = default_error_probability + exact_match_log_p  # Assume every sequence before was an error,
                                                                            # but the current one is correct
            new_match_qualities = ['E' for x in range(i)] + ['M']
            new_peak = (new_peak_start_locs, new_peak_log_p, new_match_qualities)
            peaks.append(new_peak)

        ## If two peaks have the same start and end, use only the one that has the greatest probability
        max_prob_peaks_dict = defaultdict(lambda: -np.inf)
        peaks_dict = {}
        for peak in peaks:
            peak_key = (peak[0][0], peak[0][-1])
            peak_prob = peak[1]
            if peak_prob > max_prob_peaks_dict[peak_key]:
                max_prob_peaks_dict[peak_key] = peak_prob
                peaks_dict[peak_key] = peak
            else:
                pass
        peaks = peaks_dict.values()
    return peaks

def map_end(read_end, key_length, genome_hash):
    """
    Cut the read into disjoint pieces of length
    key_length, and try to align them using the hash.

    Input:
    read_end,    the bases in one end of a paired-end read
    key_length,  the length of the keys used in the genome_hash
    genome_hash, a hash of the reference genome that returns the
                 starting position of the match for each
                 of the exact matches of each key in the genome.

    Output: [list of peaks] peaks defined up top.
    """
    all_locations = []
    for i in range(len(read_end)/key_length):
        offset = i*key_length
        key = read_end[offset: offset + key_length]
        locations = [start_loc - offset for start_loc in genome_hash[key]]
        all_locations.append(locations)
    peaks = locations_to_peaks(all_locations)
    print all_locations

    for p in peaks:
        print p

    check_peaks_against_reference(peaks, read_end, read_length, reference)
    return peaks

def check_peaks_against_reference(peaks, read, read_length, reference):
    """
    Using the peaks as a guide, we check the read against the reference.
    First, we set a cutoff for the quality of the alignment
      that is, it must be at least more likely than the average likelihood
      of an entire random genome aligning to this particular read.

      That probability is |N|*p_0, where p_0 is the probability that
      nothing aligns. ----Eh, I'm not sure about this number yet, but it seems like a good cutoff for now.

    Once the peaks have been filtered, each peak is attempted to be aligned with the
    genome. Perfectly-matching strings are skipped, and imperfectly matching strings are mapped using
    a Smith-Waterman dynamic programming algorithm.
    """
    null_alignment_log_p = min([peak[1] for peak in peaks])
    ref_length = len(reference)
    log_p_cutoff = math.log(ref_length) + null_alignment_log_p
    peaks = [peak for peak in peaks if peak[1] > log_p_cutoff]


    for peak in peaks:
        peak_CIGAR = ''
        unaligned_ref_start = np.nan
        unaligned_ref_end = np.nan
        unaligned_read_start = np.nan
        unaligned_read_end = np.nan
        offsets = peak[0]
        for i in range(len(offsets)):
            read_start = i*read_length
            offset = offsets[i]
            alignment_start = offset + read_start
            alignment_quality = peak[2][i]
            if alignment_quality == 'E':
                if unaligned_read_start is np.nan:
                    unaligned_ref_start = alignment_start
                    unaligned_read_start = read_start
                else:
                    pass

                if i == len(offsets) - 1:
                    unaligned_ref_end = alignment_start + read_length   # Note that it is not necessarily the
                                                                        # case that the unaligned
                                                                        # read should end exactly where the alignment
                                                                        # ends, but fuck it for now.
                    unaligned_read_end = read_start + read_length

                    ref_seq = reference[unaligned_ref_start: unaligned_ref_end]
                    read_seq = read[unaligned_read_start: unaligned_read_end]

                    segment_CIGAR = smith_waterman(ref_seq, read_seq)
                    unaligned_read_start = np.nan
                    unaligned_read_end = np.nan

                else:
                    segment_CIGAR = ''
            else: # First, clear the error-reads if necessary
                unaligned

            if alignment_quality == 'M':
                if unaligned_read_start is not np.nan:
                    segment_CIGAR = smith_waterman(unaligned_read_start, unaligned_read_end, reference)
                else:
                    segment_CIGAR = ''
                segment_CIGAR += 'M' + str(read_length)
            elif alignment_quality == 'E':
                segment_CIGAR = smith_waterman()
            elif any(x in alignment_quality for x in ('I', 'D')):  # If an insertion or deletion was noticed,
                indel_length = int(alignment_quality[1:])          # check that there is a record of the indel
                                                                   # earlier in the peak_CIGAR.
                segment_CIGAR = 'M' + str(read_length)
            else:
                raise

            peak_CIGAR += CIGAR_append(peak_CIGAR, segment_CIGAR)

    return


def CIGAR_append(start_CIGAR, new_CIGAR):
    """
    Appends the CIGAR-formatted
    """

    return


def smith_waterman(read1, read2):
    """
    Does Smith-Waterman dynamic-programming alignment and returns the
    most likely global alignment of the reads read1 and read2, and
    returns the CIGAR representation of the output
    """
    cigar = ''
    return cigar


def align_paired_peaks(peaks1, peaks2, read_length):
    """
    Aligns pairs of peaks, and returns ONE of the following:
    1) the sequence of aligned points for the two reads plus the exact distance between the reads
    2) a flag indicating that the read looks like it aligns, but not in a clean way, for example
        i) One end aligns well, the other doesn't
        ii) Both reads align well, but the distance between them is too large
        iii) There are multiple potential alignments that are about equally good.
        iv)  ???
    3) None, indicating that the read does not align to the genome at all.
    """


    return


def pair_peaks(peaks1, peaks2, read_length):
    peak_pairs = []
    for peak1 in peaks1:
        for peak2 in peaks2:
            start_dist = abs(peak2[0] - peak1[0])
            if MIN_DIST_BETWEEN_READS <= start_dist <= MAX_DIST_BETWEEN_READS:  # This criteria should be
                                                                                # made flexible eventually.

                peak_pairs.append((peak1, peak2))
    return peak_pairs


def map_read(paired_end_read, key_length, hash_table):
    """
    Maps a single paired-end read to the genome.
    Each end is mapped to a set of "probabilistic" peaks (the numbers aren't really probabilities)
    Then the ends are aligned to each other, and the alignment is returned.
    """
    end1 = paired_end_read[0]
    end2 = paired_end_read[1]
    peaks1 = map_end(end1, key_length, hash_table)
    peaks2 = map_end(end2, key_length, hash_table)
    output = pair_peaks(peaks1, peaks2)
    return


def read_and_map_reads(reads_fn, key_length, genome_hash):
    """
    Maps a whole bunch of paired-end reads to a reference genome.
    """
    with open(reads_fn, 'r') as reads_file:
        reads_file.readline()
        reads_file.readline()
        count = 0
        for line in reads_file:
            paired_end_read = line.strip().split(',')
            map_read(paired_end_read, key_length, genome_hash)
            count += 1
            if count > 100:
                break


if __name__ == "__main__":
    input_folder = './EE_genome'
    ref = 'ref_genomeEExample.txt'
    reads = 'reads_genomeEExample.txt'
    ref_fn = os.path.join(input_folder, ref)
    reads_fn = os.path.join(input_folder, reads)
    key_length = 10
    reference = read_reference(ref_fn)
    genome_hash = hash_reference(ref_fn, key_length)

    read_and_map_reads(reads_fn,key_length,genome_hash)